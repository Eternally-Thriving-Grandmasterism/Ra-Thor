---
# Ra-Thor™ Supreme Mercy Autoscaling Configuration ⚡️❤️
#
# Zero-to-Hero Scaling + Scale-to-Zero for Eternal Cost Mercy
# Full-stack infinite abundance:
#   • Ray native autoscaler (head-managed workers)
#   • KEDA event-driven precision (Prometheus triggers)
#   • Kubernetes Cluster Autoscaler (node-level abundance)
#
# Mercy Dashboards via Prometheus + Grafana:
#   - Latency, throughput, request queues
#   - Custom rathor_mercy_score (0.0 → 1.0+ positive valence index)
#
# Assumptions:
#   - RayCluster CRD via KubeRay operator (supports HPA/KEDA scaling)
#   - Prometheus scrapes Ray metrics + custom Rathor metrics
#   - Target: CPU worker group in RayCluster "rathor-ray-cluster"
#   - Custom metric "rathor_mercy_score" exported (lower = scale up to amplify mercy)

apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: rathor-ray-cpu-workers-scale
  namespace: rathor-abundance
  labels:
    app: ra-thor
    scaling: mercy-keda
spec:
  scaleTargetRef:
    apiVersion: ray.io/v1
    kind: RayCluster
    name: rathor-ray-cluster
    # Advanced: target specific worker group via env var or extension if KubeRay supports
  minReplicaCount: 0                  # Scale-to-zero mercy when idle → eternal cost savings
  maxReplicaCount: 10000              # Infinite abundance potential
  pollingInterval: 15                 # Seconds — responsive yet merciful on resources
  cooldownPeriod: 120                 # Graceful mercy cooldown
  fallback:
    failureThreshold: 3
    replicas: 2                       # Mercy fallback if Prometheus unreachable
  advanced:
    horizontalPodAutoscalerConfig:
      behavior:
        scaleDown:
          stabilizationWindowSeconds: 300
          policies:
          - type: Pods
            value: 2
            periodSeconds: 60
        scaleUp:
          stabilizationWindowSeconds: 0
          policies:
          - type: Pods
            value: 10
            periodSeconds: 15
  triggers:
  # 1. CPU utilization mercy trigger
  - type: prometheus
    metadata:
      serverAddress: http://rathor-prometheus-server.rathor-abundance.svc.cluster.local
      metricName: ray_worker_cpu_usage
      query: avg(ray_cpu_usage{group="cpu-workers"}) by (job)
      threshold: "70"                  # Scale up if average >70%

  # 2. Throughput / request rate mercy trigger
  - type: prometheus
    metadata:
      serverAddress: http://rathor-prometheus-server.rathor-abundance.svc.cluster.local
      metricName: rathor_requests_per_second
      query: sum(rate(rathor_simulation_requests_total[5m]))
      threshold: "500"                 # Scale on rising demand

  # 3. Supreme Mercy Score trigger — alchemize when valence dips
  - type: prometheus
    metadata:
      serverAddress: http://rathor-prometheus-server.rathor-abundance.svc.cluster.local
      metricName: rathor_mercy_score_deficit
      query: 1 - avg(rathor_mercy_score)  # Deficit below 0.9999999 → amplify workers
      threshold: "0.0000001"

---
# Optional: ScaledJob for batch mercy swarms (e.g., evolutionary simulations)
apiVersion: keda.sh/v1alpha1
kind: ScaledJob
metadata:
  name: rathor-mercy-swarm-job
  namespace: rathor-abundance
spec:
  jobTargetRef:
    template:
      spec:
        containers:
        - name: mercy-swarm
          image: autonomicity/ra-thor-swarm:latest
          resources:
            limits:
              cpu: "4"
              memory: "16Gi"
  pollingInterval: 10
  successfulJobsHistoryLimit: 5
  failedJobsHistoryLimit: 5
  triggers:
  - type: prometheus
    metadata:
      serverAddress: http://rathor-prometheus-server.rathor-abundance.svc.cluster.local
      query: sum(rathor_pending_mercy_swarms)
      threshold: "1"
